{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this assignment you will perform unsupervised learning through 4 different clustering algorithms, you will carry on this task with Iris dataset and toy datasets, to compare between these different approaches, you will employ different metrics, such as accuracy and Xie-beni index. By the end of this tutorial you are expected to achieve the following learning goals:\n",
    "\n",
    "\n",
    "### Learning goals:\n",
    "After this tutorial you can:\n",
    "- perform Hierarchical clustering with different linkage settings;\n",
    "- Perform K-means clustering with different clusters;\n",
    "- perform FCM clustering with different clusters;\n",
    "- Visualize the inner workings of FCM using toy dataset\n",
    "- perform GK clustering with different clusters;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libraries needed for this assignment:\n",
    "\n",
    "- sklearn (install: !pip install scikit-learn)\n",
    "- skfuzzy (install: !pip install scikit-fuzzy)\n",
    "- scipy (install: !pip install scipy)\n",
    "- pandas (install: !pip install pandas)\n",
    "- numpy (install: !pip install numpy)\n",
    "- matplotlib (install: !pip install matplotlib)\n",
    "- Pyfume (install: !pip install pyfume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Please import the following libraries:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree\n",
    "from scipy.optimize import linear_sum_assignment \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "import skfuzzy as fuzz\n",
    "from scipy.linalg import norm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pyfume import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Loading the Iris dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and normalizing Iris dataset\n",
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "true_labels = iris.target  # True labels\n",
    "\n",
    "# Normalize the data using z-score\n",
    "scaler = StandardScaler()\n",
    "iris_data_normalized = scaler.fit_transform(iris_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this taks you will carry on `Agglomerative clustering` also known as Agglomerative Nesting (AGNES); it is a type of hierarchical clustering, specifically a bottom-up approach. It starts with each data point as its own individual cluster and then iteratively merges the closest clusters until all points belong to a single cluster, or until a specified number of clusters is reached.\n",
    "\n",
    "There are several methods to measure similarity between two points, for this exercise we will use the Euclidean distance. Which is measured in different ways: Single linkage, Complete linkage, Average linkage, Ward linkage.\n",
    "\n",
    "- Load and Normalize: Load the Iris dataset and apply z-score normalization to the features.\n",
    "\n",
    "- Agglomerative Clustering: Perform agglomerative clustering using single linkage with an initial distance threshold of 0.0.\n",
    "\n",
    "- Determine Optimal Threshold: Experiment with various distance thresholds (e.g., 0.0, 0.5, 1.0) and identify the optimal threshold based on the accuracy metric of the clusters formed.\n",
    "\n",
    "- Visualize Dendrograms: Create two subplots: A truncated dendrogram showing the top 3 levels with the chosen threshold marked, and a full dendrogram displaying all levels.\n",
    "\n",
    "- Scatter Plot: Plot a scatter diagram using two selected features from the Iris dataset, coloring points by the optimal clusters and the actual classes.\n",
    "\n",
    "- Find the optimal distance threshold when using complete and average linkage.\n",
    "\n",
    "- Discussion: Reflect on the optimal distance threshold, the number of clusters formed, and how well the clusters correspond to the actual classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Single Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Perform agglomerative clustering with single linkage and zero distance threshold`\n",
    "\n",
    "When performing agglomerative clustering with single linkage and a zero distance threshold, your clustering function should return the following:\n",
    "\n",
    "1. **Linkage Matrix (`Z`)**: The hierarchical clustering encoded as a linkage matrix, which can be obtained using the <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html\" target=\"_blank\">`linkage`</a> function from `scipy.cluster.hierarchy`.\n",
    "\n",
    "2. **Cluster Labels (`clusters`)**: An array containing the cluster labels for each data point, based on the specified distance threshold. You can get this by applying the <a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.cut_tree.html\" target=\"_blank\">`cut_tree`</a> function to the linkage matrix with the height parameter set to the distance threshold.\n",
    "\n",
    "3. **Distance Threshold (`distance_threshold`)**: The threshold value used for forming clusters. This is essential for plotting and should be set to zero, as specified.\n",
    "\n",
    "Returning these three variables will allow the provided plotting function to display the dendrograms accurately.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your Clustering function here\n",
    "def perform_clustering(data, method='method_of_linkage_to_be_used', distance_threshold=0.0):\n",
    "    # Perform agglomerative clustering with single linkage\n",
    "    Z = linkage()  \n",
    "\n",
    "    # Create clusters using the specified distance threshold\n",
    "    clusters = cut_tree().flatten() #the flatten() operation is used to convert the output of the cut_tree() function, which is typically a 2D array, into a 1D array (or vector) of cluster labels.\n",
    "\n",
    "    # Count the number of unique clusters\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    print(f\"Number of clusters formed: {num_clusters}\")\n",
    "\n",
    "    # Return the linkage matrix, cluster labels, and distance threshold\n",
    "    return \n",
    "    \n",
    "# return Z, clusters, distance_threshold = perform_clustering()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Use the following plotting function to visualize your dendrograms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotting function\n",
    "def plot_dendrogram(Z, clusters, distance_threshold=0.0):\n",
    "    # Create a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot the truncated dendrogram (top 3 levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode='level',  \n",
    "               p=3,                    \n",
    "               labels=clusters,        \n",
    "               leaf_rotation=0,        \n",
    "               leaf_font_size=10,      \n",
    "               ax=axs[0])              \n",
    "    axs[0].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[0].set_title(\"Dendrogram (Top 3 Levels)\")\n",
    "    axs[0].set_xlabel(\"Sample Index or Cluster\")\n",
    "    axs[0].set_ylabel(\"Distance\")\n",
    "\n",
    "    # Plot the full dendrogram (all levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode=None,  \n",
    "               labels=clusters,     \n",
    "               leaf_rotation=0,     \n",
    "               leaf_font_size=10,   \n",
    "               ax=axs[1],           \n",
    "               show_leaf_counts=False)  \n",
    "    axs[1].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[1].set_title(\"Dendrogram (Full)\")\n",
    "    axs[1].set_xlabel(\"\")  \n",
    "    axs[1].set_ylabel(\"Distance\")\n",
    "    axs[1].set_xticks([])\n",
    "\n",
    "    # Set the main title for the entire figure\n",
    "    plt.suptitle(\"Dendrograms Single Linkage Zero Distance Threshold\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Use the results for plotting\n",
    "plot_dendrogram(Z, clusters, distance_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Using the following accuracy function to answer the following questions`\n",
    "- What is the optimal distance threshold yielding the best accuracy?\n",
    "- What is the distance threshold yielding 3 clusters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set distance threshold, replace 0 value with your value\n",
    "distance_threshold = 0.05\n",
    "\n",
    "# Define the function to calculate accuracy\n",
    "def calculate_accuracy(clusters, true_labels):\n",
    "    cm = confusion_matrix(true_labels, clusters)\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    return accuracy\n",
    "\n",
    "# Function to perform clustering based on a manually entered threshold\n",
    "def manual_threshold_clustering(Z, true_labels, distance_threshold):\n",
    "    # Create clusters using the specified distance threshold\n",
    "    clusters = cut_tree(Z, height=distance_threshold).flatten()\n",
    "    \n",
    "    # Count the number of unique clusters\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = calculate_accuracy(clusters, true_labels)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Distance Threshold: {distance_threshold}\")\n",
    "    print(f\"Number of clusters formed: {num_clusters}\")\n",
    "    print(f\"Accuracy achieved: {accuracy:.4f}\")\n",
    "    \n",
    "    # Plot the dendrogram\n",
    "    plot_dendrogram(Z, clusters, distance_threshold)\n",
    "\n",
    "# Dendrogram plotting function\n",
    "def plot_dendrogram(Z, clusters, distance_threshold):\n",
    "    # Create a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot the truncated dendrogram (top 3 levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode='level',  \n",
    "               p=3,                    \n",
    "               leaf_rotation=0,        \n",
    "               leaf_font_size=10,      \n",
    "               ax=axs[0])              \n",
    "    axs[0].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[0].set_title(\"Dendrogram (Top 3 Levels)\")\n",
    "    axs[0].set_xlabel(\"Sample Index or Cluster\")\n",
    "    axs[0].set_ylabel(\"Distance\")\n",
    "\n",
    "    # Plot the full dendrogram (all levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode=None,  \n",
    "               labels=clusters,     \n",
    "               leaf_rotation=0,     \n",
    "               leaf_font_size=10,   \n",
    "               ax=axs[1],           \n",
    "               show_leaf_counts=False)  \n",
    "    axs[1].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[1].set_title(\"Dendrogram (Full)\")\n",
    "    axs[1].set_xlabel(\"\")  \n",
    "    axs[1].set_ylabel(\"Distance\")\n",
    "    axs[1].set_xticks([])\n",
    "\n",
    "    # Set the main title for the entire figure\n",
    "    plt.suptitle(\"Dendrograms with Distance Threshold\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Ask for manual input of the distance threshold\n",
    "manual_threshold_clustering(Z, true_labels, distance_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Based on your experiments, set the best_threshold value as the distance threshold resulting in 3 clusters to visualize Iris (Petal width and Petal length)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 1.2\n",
    "\n",
    "\n",
    "# Perform agglomerative clustering with single linkage\n",
    "Z = linkage(iris_data_normalized, method='single')\n",
    "\n",
    "\n",
    "# Find the number of clusters formed with the best threshold\n",
    "best_clusters = cut_tree(Z, height=best_threshold).flatten()\n",
    "num_clusters = len(np.unique(best_clusters))\n",
    "\n",
    "print(f\"Best Distance Threshold: {best_threshold}\")\n",
    "print(f\"Number of clusters formed: {num_clusters}\")\n",
    "\n",
    "# Define marker shapes for each cluster\n",
    "markers = ['o', 's', 'D', 'X']  # Circle, Square, Diamond, X\n",
    "colors = ['r', 'g', 'b']  # Colors for true labels (0, 1, 2)\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot clusters with different shapes\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_points = iris_data_normalized[best_clusters == cluster]\n",
    "    \n",
    "    # Use the third and fourth features (Petal length and Petal width)\n",
    "    axs[0].scatter(\n",
    "        cluster_points[:, 2],  # Petal length\n",
    "        cluster_points[:, 3],  # Petal width\n",
    "        marker=markers[cluster % len(markers)],  # Different shape for each cluster\n",
    "        label=f'Cluster {cluster}'\n",
    "    )\n",
    "\n",
    "axs[0].set_title('Clusters Visualization')\n",
    "axs[0].set_xlabel('Petal Length (standardized)')\n",
    "axs[0].set_ylabel('Petal Width (standardized)')\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot true labels with different colors\n",
    "for label in np.unique(true_labels):\n",
    "    label_points = iris_data_normalized[true_labels == label]\n",
    "    \n",
    "    axs[1].scatter(\n",
    "        label_points[:, 2],  # Petal length\n",
    "        label_points[:, 3],  # Petal width\n",
    "        label=f'Class {label}',\n",
    "        alpha=0.5  # Slight transparency for better visualization\n",
    "    )\n",
    "\n",
    "axs[1].set_title('True Labels Visualization')\n",
    "axs[1].set_xlabel('Petal Length (standardized)')\n",
    "axs[1].set_ylabel('Petal Width (standardized)')\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "\n",
    "# Set the main title for the entire figure\n",
    "plt.suptitle(\"Single Linkage Optimal Distance Threshold\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to reserve space for the main title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Complete linkage\n",
    "Perform agglomerative clustering using complete linkage. In a similar manner find the optimal distance threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering function\n",
    "def perform_clustering(data, method='method_of_linkage_to_be_used', distance_threshold=0.0):\n",
    "    # Perform agglomerative clustering with single linkage\n",
    "    Z = linkage()  \n",
    "\n",
    "    # Create clusters using the specified distance threshold\n",
    "    clusters = cut_tree().flatten()\n",
    "\n",
    "    # Count the number of unique clusters\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    print(f\"Number of clusters formed: {num_clusters}\")\n",
    "\n",
    "    # Return the linkage matrix, cluster labels, and distance threshold\n",
    "    return \n",
    "\n",
    "\n",
    "# return Z, clusters, distance_threshold = perform_clustering()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visualize your dendograms and experiment with the distance threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set distance threshold, replace 0 value with your value\n",
    "distance_threshold = 0.05\n",
    "\n",
    "# Define the function to calculate accuracy\n",
    "def calculate_accuracy(clusters, true_labels):\n",
    "    cm = confusion_matrix(true_labels, clusters)\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    return accuracy\n",
    "\n",
    "# Function to perform clustering based on a manually entered threshold\n",
    "def manual_threshold_clustering(Z, true_labels, distance_threshold):\n",
    "    # Create clusters using the specified distance threshold\n",
    "    clusters = cut_tree(Z, height=distance_threshold).flatten()\n",
    "    \n",
    "    # Count the number of unique clusters\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = calculate_accuracy(clusters, true_labels)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Distance Threshold: {distance_threshold}\")\n",
    "    print(f\"Number of clusters formed: {num_clusters}\")\n",
    "    print(f\"Accuracy achieved: {accuracy:.4f}\")\n",
    "    \n",
    "    # Plot the dendrogram\n",
    "    plot_dendrogram(Z, clusters, distance_threshold)\n",
    "\n",
    "# Dendrogram plotting function\n",
    "def plot_dendrogram(Z, clusters, distance_threshold):\n",
    "    # Create a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot the truncated dendrogram (top 3 levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode='level',  \n",
    "               p=3,                    \n",
    "               leaf_rotation=0,        \n",
    "               leaf_font_size=10,      \n",
    "               ax=axs[0])              \n",
    "    axs[0].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[0].set_title(\"Dendrogram (Top 3 Levels)\")\n",
    "    axs[0].set_xlabel(\"Sample Index or Cluster\")\n",
    "    axs[0].set_ylabel(\"Distance\")\n",
    "\n",
    "    # Plot the full dendrogram (all levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode=None,  \n",
    "               labels=clusters,     \n",
    "               leaf_rotation=0,     \n",
    "               leaf_font_size=10,   \n",
    "               ax=axs[1],           \n",
    "               show_leaf_counts=False)  \n",
    "    axs[1].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[1].set_title(\"Dendrogram (Full)\")\n",
    "    axs[1].set_xlabel(\"\")  \n",
    "    axs[1].set_ylabel(\"Distance\")\n",
    "    axs[1].set_xticks([])\n",
    "\n",
    "    # Set the main title for the entire figure\n",
    "    plt.suptitle(\"Dendrograms with Distance Threshold\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Ask for manual input of the distance threshold\n",
    "manual_threshold_clustering(Z, true_labels, distance_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visuliaze Iris dataset using your distance threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 1.30\n",
    "\n",
    "# Perform agglomerative clustering with single linkage\n",
    "Z = linkage(iris_data_normalized, method='complete')\n",
    "\n",
    "\n",
    "# Find the number of clusters formed with the best threshold\n",
    "best_clusters = cut_tree(Z, height=best_threshold).flatten()\n",
    "num_clusters = len(np.unique(best_clusters))\n",
    "\n",
    "print(f\"Best Distance Threshold: {best_threshold}\")\n",
    "print(f\"Number of clusters formed: {num_clusters}\")\n",
    "\n",
    "# Define marker shapes for each cluster\n",
    "markers = ['o', 's', 'D', 'X']  # Circle, Square, Diamond, X\n",
    "colors = ['r', 'g', 'b']  # Colors for true labels (0, 1, 2)\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot clusters with different shapes\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_points = iris_data_normalized[best_clusters == cluster]\n",
    "    \n",
    "    # Use the third and fourth features (Petal length and Petal width)\n",
    "    axs[0].scatter(\n",
    "        cluster_points[:, 2],  # Petal length\n",
    "        cluster_points[:, 3],  # Petal width\n",
    "        marker=markers[cluster % len(markers)],  # Different shape for each cluster\n",
    "        label=f'Cluster {cluster}'\n",
    "    )\n",
    "\n",
    "axs[0].set_title('Clusters Visualization')\n",
    "axs[0].set_xlabel('Petal Length (standardized)')\n",
    "axs[0].set_ylabel('Petal Width (standardized)')\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot true labels with different colors\n",
    "for label in np.unique(true_labels):\n",
    "    label_points = iris_data_normalized[true_labels == label]\n",
    "    \n",
    "    axs[1].scatter(\n",
    "        label_points[:, 2],  # Petal length\n",
    "        label_points[:, 3],  # Petal width\n",
    "        label=f'Class {label}',\n",
    "        alpha=0.5  # Slight transparency for better visualization\n",
    "    )\n",
    "\n",
    "axs[1].set_title('True Labels Visualization')\n",
    "axs[1].set_xlabel('Petal Length (standardized)')\n",
    "axs[1].set_ylabel('Petal Width (standardized)')\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "\n",
    "# Set the main title for the entire figure\n",
    "plt.suptitle(\"Single Linkage Optimal Distance Threshold\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to reserve space for the main title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.3: Average linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Perform as the previous exercise but this time use an average linkage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create average clustering fuction\n",
    "# Clustering function\n",
    "def perform_clustering(data, method='method_of_linkage_to_be_used', distance_threshold=0.0):\n",
    "    # Perform agglomerative clustering with single linkage\n",
    "    Z = linkage()\n",
    "    \n",
    "    # Create clusters using the specified distance threshold\n",
    "    clusters = cut_tree().flatten()\n",
    "    \n",
    "    # Count the number of unique clusters\n",
    "    num_clusters = \n",
    "    print(f\"Number of clusters formed: {num_clusters}\")\n",
    "    \n",
    "    # Return the linkage matrix, cluster labels, and distance threshold\n",
    "    return \n",
    "\n",
    "# return Z, clusters, distance_threshold = perform_clustering()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visualize your dendograms and experiment with the distance threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set distance threshold, replace 0 value with your value\n",
    "distance_threshold = 0.5\n",
    "\n",
    "# Define the function to calculate accuracy\n",
    "def calculate_accuracy(clusters, true_labels):\n",
    "    cm = confusion_matrix(true_labels, clusters)\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    return accuracy\n",
    "\n",
    "# Function to perform clustering based on a manually entered threshold\n",
    "def manual_threshold_clustering(Z, true_labels, distance_threshold):\n",
    "    # Create clusters using the specified distance threshold\n",
    "    clusters = cut_tree(Z, height=distance_threshold).flatten()\n",
    "    \n",
    "    # Count the number of unique clusters\n",
    "    num_clusters = len(np.unique(clusters))\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = calculate_accuracy(clusters, true_labels)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Distance Threshold: {distance_threshold}\")\n",
    "    print(f\"Number of clusters formed: {num_clusters}\")\n",
    "    print(f\"Accuracy achieved: {accuracy:.4f}\")\n",
    "    \n",
    "    # Plot the dendrogram\n",
    "    plot_dendrogram(Z, clusters, distance_threshold)\n",
    "\n",
    "# Dendrogram plotting function\n",
    "def plot_dendrogram(Z, clusters, distance_threshold):\n",
    "    # Create a figure with two subplots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Plot the truncated dendrogram (top 3 levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode='level',  \n",
    "               p=3,                    \n",
    "               leaf_rotation=0,        \n",
    "               leaf_font_size=10,      \n",
    "               ax=axs[0])              \n",
    "    axs[0].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[0].set_title(\"Dendrogram (Top 3 Levels)\")\n",
    "    axs[0].set_xlabel(\"Sample Index or Cluster\")\n",
    "    axs[0].set_ylabel(\"Distance\")\n",
    "\n",
    "    # Plot the full dendrogram (all levels)\n",
    "    dendrogram(Z, \n",
    "               truncate_mode=None,  \n",
    "               labels=clusters,     \n",
    "               leaf_rotation=0,     \n",
    "               leaf_font_size=10,   \n",
    "               ax=axs[1],           \n",
    "               show_leaf_counts=False)  \n",
    "    axs[1].axhline(y=distance_threshold, color='r', linestyle='--')\n",
    "    axs[1].set_title(\"Dendrogram (Full)\")\n",
    "    axs[1].set_xlabel(\"\")  \n",
    "    axs[1].set_ylabel(\"Distance\")\n",
    "    axs[1].set_xticks([])\n",
    "\n",
    "    # Set the main title for the entire figure\n",
    "    plt.suptitle(\"Dendrograms with Distance Threshold\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Ask for manual input of the distance threshold\n",
    "manual_threshold_clustering(Z, true_labels, distance_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Visualize iris dataset with 3 cluster and your distance threshold`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshold = 1.30\n",
    "\n",
    "\n",
    "\n",
    "# Perform agglomerative clustering with single linkage\n",
    "Z = linkage(iris_data_normalized, method='average')\n",
    "\n",
    "\n",
    "# Find the number of clusters formed with the best threshold\n",
    "best_clusters = cut_tree(Z, height=best_threshold).flatten()\n",
    "num_clusters = len(np.unique(best_clusters))\n",
    "\n",
    "print(f\"Best Distance Threshold: {best_threshold}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")\n",
    "print(f\"Number of clusters formed: {num_clusters}\")\n",
    "\n",
    "# Define marker shapes for each cluster\n",
    "markers = ['o', 's', 'D', 'X']  # Circle, Square, Diamond, X\n",
    "colors = ['r', 'g', 'b']  # Colors for true labels (0, 1, 2)\n",
    "\n",
    "# Create a figure with two subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot clusters with different shapes\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_points = iris_data_normalized[best_clusters == cluster]\n",
    "    \n",
    "    # Use the third and fourth features (Petal length and Petal width)\n",
    "    axs[0].scatter(\n",
    "        cluster_points[:, 2],  # Petal length\n",
    "        cluster_points[:, 3],  # Petal width\n",
    "        marker=markers[cluster % len(markers)],  # Different shape for each cluster\n",
    "        label=f'Cluster {cluster}'\n",
    "    )\n",
    "\n",
    "axs[0].set_title('Clusters Visualization')\n",
    "axs[0].set_xlabel('Petal Length (standardized)')\n",
    "axs[0].set_ylabel('Petal Width (standardized)')\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot true labels with different colors\n",
    "for label in np.unique(true_labels):\n",
    "    label_points = iris_data_normalized[true_labels == label]\n",
    "    \n",
    "    axs[1].scatter(\n",
    "        label_points[:, 2],  # Petal length\n",
    "        label_points[:, 3],  # Petal width\n",
    "        label=f'Class {label}',\n",
    "        alpha=0.5  # Slight transparency for better visualization\n",
    "    )\n",
    "\n",
    "axs[1].set_title('True Labels Visualization')\n",
    "axs[1].set_xlabel('Petal Length (standardized)')\n",
    "axs[1].set_ylabel('Petal Width (standardized)')\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "\n",
    "# Set the main title for the entire figure\n",
    "plt.suptitle(\"Single Linkage Optimal Distance Threshold\")\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to reserve space for the main title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Perform K-means clustering on Iris dataset\n",
    "\n",
    "In this exercise, you will apply K-means clustering to the Iris dataset and analyze how the number of clusters affects the clustering accuracy. Follow these steps:\n",
    "\n",
    "1. Implement K-means clustering for a range of cluster numbers (from 1 to 10).\n",
    "2. Evaluate the clustering accuracy for each number of clusters.\n",
    "3. Visualize the results to determine the optimal number of clusters.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "1. Create a loop that iterates through the range of cluster numbers (1 to 10).\n",
    "2. For each iteration:\n",
    "   a. Perform K-means clustering using `sklearn.cluster.KMeans`.\n",
    "   b. Use the `fit_predict` method to obtain cluster assignments.\n",
    "   c. Store the cluster assignments in a list called `kmeans_results`.\n",
    "3. Calculate the accuracy for each clustering result.\n",
    "4. Generate a plot showing:\n",
    "   a. The number of clusters vs. clustering accuracy.\n",
    "   b. A scatter plot of the Iris data using Petal Length and Petal Width, colored by:\n",
    "      - The cluster assignments for the optimal number of clusters.\n",
    "      - The true class labels.\n",
    "\n",
    "This exercise will help you understand how the choice of cluster number affects K-means performance and how well the algorithm can recover the natural classes in the Iris dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To facilitate this task we created the accuracy and visualization functions for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-means\n",
    "# Redefining the cluster_range for plotting process\n",
    "cluster_range = range()\n",
    "\n",
    "# Perform K-means clustering for each number of clusters\n",
    "kmeans_results = []\n",
    "for n_clusters in cluster_range:\n",
    "    kmeans = KMeans()\n",
    "    clusters = kmeans.fit_predict()\n",
    "    kmeans_results.append()\n",
    "\n",
    "# return kmeans_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run the following code for accuary and visulaization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracies separately\n",
    "accuracies = []\n",
    "for clusters in kmeans_results:\n",
    "    # Using sklearn's confusion_matrix to generate the contingency matrix\n",
    "    contingency_matrix = confusion_matrix(true_labels, clusters)\n",
    "\n",
    "    # For each cluster, find the maximum true label count\n",
    "    correct_predictions = sum(np.max(contingency_matrix, axis=0))\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plot setup\n",
    "fig, axs = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "# Plotting number of clusters vs. accuracy on the left subplot\n",
    "axs[0].plot(cluster_range, accuracies, marker='o', color='b', label=\"Accuracy\")\n",
    "axs[0].set_title(\"Number of Clusters vs. Accuracy\")\n",
    "axs[0].set_xlabel(\"Number of Clusters\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].set_xlim(0, 11)  # Setting x-axis limit\n",
    "axs[0].set_ylim(0, 1.1)  # Setting y-axis limit\n",
    "axs[0].set_xticks(range(0, 12))  # Setting x-ticks every 1 increment\n",
    "axs[0].set_yticks(np.arange(0, 1.1, 0.1))  # Setting y-ticks every 0.1 increment\n",
    "axs[0].grid()\n",
    "axs[0].legend()\n",
    "\n",
    "# K-means clustering with 3 clusters for visualization on the middle subplot\n",
    "kmeans_3 = KMeans(n_clusters=3, random_state=0)\n",
    "clusters_3 = kmeans_3.fit_predict(iris_data_normalized)\n",
    "\n",
    "# Plot petal length vs. petal width with round markers for clusters\n",
    "colors = ['r', 'g', 'b']  # Define colors for each cluster\n",
    "for cluster in np.unique(clusters_3):\n",
    "    cluster_points = iris_data_normalized[clusters_3 == cluster]\n",
    "    axs[1].scatter(cluster_points[:, 2], cluster_points[:, 3],\n",
    "                   color=colors[cluster],\n",
    "                   label=f'Cluster {cluster}',\n",
    "                   alpha=0.7)\n",
    "\n",
    "# Customizing the plot for petal length and width\n",
    "axs[1].set_title(\"K-means Clustering (3 Clusters) - Petal Length vs. Petal Width\")\n",
    "axs[1].set_xlabel(\"Petal Length\")\n",
    "axs[1].set_ylabel(\"Petal Width\")\n",
    "axs[1].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "axs[1].grid()\n",
    "\n",
    "# K-means clustering with class coloring on the right subplot\n",
    "for label in np.unique(true_labels):\n",
    "    label_points = iris_data_normalized[true_labels == label]\n",
    "    axs[2].scatter(label_points[:, 2], label_points[:, 3],\n",
    "                   color=colors[label],\n",
    "                   label=f'Class {label}',\n",
    "                   alpha=0.5)\n",
    "\n",
    "# Customizing the plot for petal length and width with class colors\n",
    "axs[2].set_title(\"True Labels - Petal Length vs. Petal Width\")\n",
    "axs[2].set_xlabel(\"Petal Length\")\n",
    "axs[2].set_ylabel(\"Petal Width\")\n",
    "axs[2].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "axs[2].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final clustering accuracy\n",
    "print(\"Clustering Accuracies:\", accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Fuzzy C-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Perform C-means clustering on Iris dataset\n",
    "In this exercise you will perform C-means clustering on Iris dataset, test with up to 10 clusters and investigate how your choices affect accuracy. Generate a plot visualizing the optimal number of clusters using Petal Length and Width.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "1. Create a loop that iterates through a range of cluster numbers from 1 to 10, cluster_range = range(1, 11).\n",
    "\n",
    "2. For each number of clusters:\n",
    "\n",
    "   a. Perform Fuzzy C-Means clustering using the <a href=\"https://pythonhosted.org/scikit-fuzzy/api/skfuzzy.cluster.html\" target=\"_blank\">`fuzz.cluster.cmeans()`</a> function from the skfuzzy library.\n",
    "   \n",
    "   b. Use the normalized Iris data (`iris_data_normalized.T`) as input.\n",
    "   \n",
    "   c. Set the fuzziness coefficient (m) to 2.\n",
    "   \n",
    "   d. Use an error threshold of 0.005 and a maximum of 1000 iterations.\n",
    "   \n",
    "   e. Extract the cluster centers and membership matrix from the FCM results.\n",
    "   \n",
    "   f. Assign each data point to the cluster with the highest membership value.\n",
    "   \n",
    "   g. Store the cluster assignments in a list called `all_clusters`.\n",
    "   \n",
    "3. Your function should return:\n",
    "\n",
    "   - `all_clusters`: A list of numpy arrays, where each array contains the cluster assignments for a specific number of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefining the cluster_range and accuracies for plotting process\n",
    "cluster_range = range()\n",
    "accuracies = []\n",
    "all_clusters = []\n",
    "\n",
    "# Perform Fuzzy C-Means clustering for each number of clusters\n",
    "for n_clusters in cluster_range:\n",
    "    # Perform fuzzy C-means clustering\n",
    "    cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans()\n",
    "    \n",
    "    # Assign clusters based on the highest membership\n",
    "    clusters = np.argmax()\n",
    "    all_clusters.append()\n",
    "\n",
    "# return all_clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate accuracies for each clustering result\n",
    "for clusters in all_clusters:\n",
    "    # Using sklearn's confusion_matrix to generate the contingency matrix\n",
    "    contingency_matrix = confusion_matrix(true_labels, clusters)\n",
    "    \n",
    "    # For each cluster, find the maximum true label count\n",
    "    correct_predictions = sum(np.max(contingency_matrix, axis=0))\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plot setup\n",
    "fig, axs = plt.subplots(1, 3, figsize=(24, 6))\n",
    "\n",
    "# Plotting number of clusters vs. accuracy on the left subplot\n",
    "axs[0].plot(cluster_range, accuracies, marker='o', color='b', label=\"Accuracy\")\n",
    "axs[0].set_title(\"Number of Clusters vs. Accuracy\")\n",
    "axs[0].set_xlabel(\"Number of Clusters\")\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "axs[0].set_xlim(0, 11)  # Setting x-axis limit\n",
    "axs[0].set_ylim(0, 1.1)  # Setting y-axis limit\n",
    "axs[0].set_xticks(range(0, 12))  # Setting x-ticks every 1 increment\n",
    "axs[0].set_yticks(np.arange(0, 1.1, 0.1))  # Setting y-ticks every 0.1 increment\n",
    "axs[0].grid()\n",
    "axs[0].legend()\n",
    "\n",
    "# Fuzzy C-means clustering with 3 clusters for visualization on the middle subplot\n",
    "n_clusters_3 = 3\n",
    "cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(iris_data_normalized.T, n_clusters_3, 2, error=0.005, maxiter=1000)\n",
    "clusters_3 = np.argmax(u, axis=0)\n",
    "\n",
    "# Plot petal length vs. petal width with round markers for clusters\n",
    "colors = ['r', 'g', 'b']  # Define colors for each cluster\n",
    "for cluster in np.unique(clusters_3):\n",
    "    cluster_points = iris_data_normalized[clusters_3 == cluster]\n",
    "    axs[1].scatter(cluster_points[:, 2], cluster_points[:, 3],\n",
    "                   color=colors[cluster],\n",
    "                   label=f'Cluster {cluster}',\n",
    "                   alpha=0.7)\n",
    "\n",
    "# Customizing the plot for petal length and width\n",
    "axs[1].set_title(\"Fuzzy C-means Clustering (3 Clusters) - Petal Length vs. Petal Width\")\n",
    "axs[1].set_xlabel(\"Petal Length\")\n",
    "axs[1].set_ylabel(\"Petal Width\")\n",
    "axs[1].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "axs[1].grid()\n",
    "\n",
    "# Fuzzy C-means clustering with class coloring on the right subplot\n",
    "for label in np.unique(true_labels):\n",
    "    label_points = iris_data_normalized[true_labels == label]\n",
    "    axs[2].scatter(label_points[:, 2], label_points[:, 3],\n",
    "                   color=colors[label],\n",
    "                   label=f'Class {label}',\n",
    "                   alpha=0.5)\n",
    "\n",
    "# Customizing the plot for petal length and width with class colors\n",
    "axs[2].set_title(\"True Labels - Petal Length vs. Petal Width\")\n",
    "axs[2].set_xlabel(\"Petal Length\")\n",
    "axs[2].set_ylabel(\"Petal Width\")\n",
    "axs[2].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "axs[2].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final clustering accuracy\n",
    "print(\"Clustering Accuracies:\", accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Visualize membership matrix from toy datset\n",
    "In this exercise, you will create a single-variable dataset named `data_points` consisting of 200 equally spaced data points within the range of 0 to 10 by using the linspace() function from Numpy library. After generating this dataset, you will apply the Fuzzy C-Means (FCM) algorithm with 5 clusters to analyze the data. Finally, you will visualize the data points against the membership values retrieved from the FCM algorithm, allowing you to observe how each data point is associated with the different clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a single variable dataset with 200 datapoints from 0 to 10\n",
    "data_points =   # 200 points from 0 to 10\n",
    "data_points = data_points.reshape(1, -1)  # Reshape for FCM\n",
    "\n",
    "# Step 2: Apply FCM with 5 clusters\n",
    "n_clusters = \n",
    "cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans()\n",
    "\n",
    "# return cluster centers cntr \n",
    "# return membership matrix u\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`use the following code to visualize the memberships`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plotting the membership values\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot membership values for each cluster\n",
    "for i in range(n_clusters):\n",
    "    plt.plot(data_points.flatten(), u[i], label=f'Cluster {i + 1}')\n",
    "\n",
    "plt.title(\"Membership Values from Fuzzy C-Means Clustering\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Membership Value\")\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.3: Estimating membership values\n",
    " \n",
    "   In addition to your existing data, add 200 points each from \\(-10\\) to \\(0\\) and \\(10\\) to \\(20\\) to create a larger dataset named extended_data_points, giving a total of 600 points spanning \\(-10\\) to \\(20\\).\n",
    "\n",
    "1. **Calculate Membership Values**:  \n",
    "   For the full range of data points, use the following formula to calculate the membership values for each cluster:\n",
    "   $$\n",
    "   \\mu_k^{(n)} = \\frac{1}{\\sum_{j=1}^C \\left(\\frac{\\|x^{(n)} - v^{(k)}\\|}{\\|x^{(n)} - v^{(j)}\\|}\\right)^{\\frac{2}{m-1}}}\n",
    "   $$\n",
    "   where \\(m = 2\\) and \\(C = 5\\).\n",
    "\n",
    "2. **Plot the Membership Values**:  \n",
    "   Visualize the membership values across the entire range. What do you observe?\n",
    "\n",
    "To achieve this task you can either use the provided formula and your previously obtained cluster centers cntr, or you can use the fuzz.cluster.cmeans_predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Extend the data range from -10 to 20\n",
    "extended_data_points =   # 300 points from -10 to 20\n",
    "extended_data_points = extended_data_points.reshape(1, -1)  # Reshape for FCM\n",
    "\n",
    "# Step 2: Calculate membership values for the extended data using the obtained cluster centers\n",
    "# Note: `cntr` is obtained from the previous code\n",
    "u_extended, _, _, _, _, _ = fuzz.cluster.cmeans_predict()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`use the following code to visualize your membership values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Plot the membership values for the extended data range\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot membership values for each cluster\n",
    "for i in range(n_clusters):\n",
    "    plt.plot(extended_data_points.flatten(), u_extended[i], label=f'Cluster {i + 1}')\n",
    "\n",
    "plt.title(\"Membership Values for Extended Data Range from Fuzzy C-Means Clustering\")\n",
    "plt.xlabel(\"Data Points\")\n",
    "plt.ylabel(\"Membership Value\")\n",
    "plt.xlim(-10, 20)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.4: Investigating Clustering Quality\n",
    "\n",
    "In this exercise, you will employ the Xie-Beni index to compare the clustering quality of Fuzzy C-means across different numbers of clusters. Then, you will use a fixed number of clusters and explore the effect of the fuzziness parameter $m$ on the clustering quality. You will use the Iris dataset for this exercise.\n",
    "\n",
    "The formula for the Xie-Beni Index is: \n",
    "\n",
    "1. **Numerator ( Cluster Compactness)**\n",
    "   \n",
    "2. **Denominator (Clusters Separation)**\n",
    "   \n",
    "### Complete Xie-Beni Index Formula\n",
    "\n",
    "Putting it all together, the complete formula for the Xie-Beni Index is:\n",
    "\n",
    "$$\n",
    "\\text{Xie-Beni Index} = \\frac{\\sum_{i=1}^{k} \\sum_{j=1}^{N} u_{ij}^m \\cdot \\|x_j - c_i\\|^2}{N \\cdot \\min_{i \\neq j} \\|c_i - c_j\\|^2}\n",
    "$$\n",
    "(ref https://doi.org/10.1109/ICoSNIKOM48755.2019.9111538)\n",
    "\n",
    "### Explanation of Variables:\n",
    "- **$N$**: Total number of data points.\n",
    "- **$k$**: Total number of clusters.\n",
    "- **$u_{ij}$**: Membership value of data point \\( j \\) in cluster \\( i \\).\n",
    "- **$m$**: Fuzziness parameter, which affects the degree of membership.\n",
    "- **$x_j$**: The data point \\( j \\).\n",
    "- **$c_i$**: The center of cluster \\( i \\).\n",
    "- **$\\|x_j - c_i\\|$**: The Euclidean distance between data point \\( j \\) and cluster center \\( i \\).\n",
    "- **$\\min_{i \\neq j} \\|c_i - c_j\\|^2$**: The minimum squared distance between any two distinct cluster centers $c_i$ and $c_j$.\n",
    "\n",
    "#### detailed Instruction:\n",
    "\n",
    "1. Compute Xie-Beni Index for varying number of clusters:\n",
    "   - Iterate through a range of cluster numbers (2 to 10)\n",
    "   - Perform Fuzzy C-Means clustering for each number of clusters\n",
    "   - Calculate the Xie-Beni Index for each clustering result\n",
    "   - Store the Xie-Beni Index values\n",
    "\n",
    "2. Plot Xie-Beni Index vs. Number of Clusters:\n",
    "   - Create a subplot\n",
    "   - Plot the Xie-Beni Index values against the number of clusters\n",
    "   - Set appropriate labels, title, and grid\n",
    "\n",
    "3. Compute Xie-Beni Index for varying fuzzification index (m):\n",
    "   - Fix the number of clusters to 3\n",
    "   - Iterate through a range of m values (2 to 10)\n",
    "   - Perform Fuzzy C-Means clustering for each m value\n",
    "   - Calculate the Xie-Beni Index for each clustering result\n",
    "   - Store the Xie-Beni Index values\n",
    "\n",
    "4. Plot Xie-Beni Index vs. Fuzzification Index:\n",
    "   - Create another subplot\n",
    "   - Plot the Xie-Beni Index values against the fuzzification index values\n",
    "   - Set appropriate labels, title, and grid\n",
    "\n",
    "5. Display the plots:\n",
    "   - Adjust the layout of the subplots\n",
    "   - Show the final figure with both plots\n",
    "\n",
    "These tasks collectively analyze the performance of Fuzzy C-Means clustering on the Iris dataset using the Xie-Beni Index as a metric, exploring how it changes with different numbers of clusters and fuzzification index values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of clusters range to test for Xie-Beni Index\n",
    "n_clusters_range = range(2, 11)\n",
    "\n",
    "# Create a figure for Xie-Beni Index with two subplots\n",
    "fig_xie_beni, axs_xie_beni = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Compute Xie-Beni Index for the Iris dataset\n",
    "xie_beni_values = []\n",
    "\n",
    "for n_clusters in n_clusters_range:\n",
    "    # Perform Fuzzy C-Means clustering\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(iris_data_normalized.T, n_clusters, m=2, error=0.005, maxiter=1000, init=None)\n",
    "\n",
    "    # Compute the distance of each data point to each cluster center\n",
    "    distances = np.linalg.norm(iris_data_normalized[:, np.newaxis] - cntr, axis=2)\n",
    "\n",
    "    # Calculate the numerator of the Xie-Beni Index\n",
    "    num = np.sum((u ** 2) * (distances ** 2).T)\n",
    "\n",
    "    # Calculate the minimum distance squared between cluster centers\n",
    "    dist_centers = np.linalg.norm(cntr[:, np.newaxis] - cntr[np.newaxis, :], axis=2)\n",
    "    min_dist = np.min(dist_centers[dist_centers > 0])  # Avoid zero distance\n",
    "\n",
    "    # Calculate the Xie-Beni Index\n",
    "    xie_beni_index = num / (iris_data_normalized.shape[0] * min_dist ** 2)\n",
    "\n",
    "    # Append the Xie-Beni Index value to the list\n",
    "    xie_beni_values.append(xie_beni_index)\n",
    "\n",
    "# Plot the Xie-Beni Index for the Iris dataset\n",
    "ax_xie_beni = axs_xie_beni[0]\n",
    "ax_xie_beni.plot(n_clusters_range, xie_beni_values, marker='o', color='blue')\n",
    "ax_xie_beni.set_xlabel('Number of Clusters')\n",
    "ax_xie_beni.set_ylabel('Xie-Beni Index')\n",
    "ax_xie_beni.set_title('Xie-Beni Index - Iris Dataset')\n",
    "ax_xie_beni.grid(True)\n",
    "ax_xie_beni.set_xticks(n_clusters_range)\n",
    "\n",
    "# Now compute the Xie-Beni Index for varying fuzzification index m\n",
    "m_values = range(2, 11)  # Start m from 2 to avoid division by zero\n",
    "fixed_n_clusters = 3  # Fixed number of clusters\n",
    "xie_beni_fuzz_values = []\n",
    "\n",
    "for m in m_values:\n",
    "    # Perform Fuzzy C-Means clustering with fixed number of clusters\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(iris_data_normalized.T, fixed_n_clusters, m=m, error=0.005, maxiter=1000, init=None)\n",
    "\n",
    "    # Compute the distance of each data point to each cluster center\n",
    "    distances = np.linalg.norm(iris_data_normalized[:, np.newaxis] - cntr, axis=2)\n",
    "\n",
    "    # Calculate the numerator of the Xie-Beni Index, now using the current m value\n",
    "    num = np.sum((u ** m) * (distances ** 2).T)\n",
    "\n",
    "    # Calculate the minimum distance squared between cluster centers\n",
    "    dist_centers = np.linalg.norm(cntr[:, np.newaxis] - cntr[np.newaxis, :], axis=2)\n",
    "    min_dist = np.min(dist_centers[dist_centers > 0])  # Avoid zero distance\n",
    "\n",
    "    # Calculate the Xie-Beni Index\n",
    "    xie_beni_index_fuzz = num / (iris_data_normalized.shape[0] * min_dist ** 2)\n",
    "\n",
    "    # Append the Xie-Beni Index value to the list\n",
    "    xie_beni_fuzz_values.append(xie_beni_index_fuzz)\n",
    "\n",
    "# Plot the Xie-Beni Index for varying fuzzification index\n",
    "ax_xie_beni_fuzz = axs_xie_beni[1]\n",
    "ax_xie_beni_fuzz.plot(m_values, xie_beni_fuzz_values, marker='o', color='orange')\n",
    "ax_xie_beni_fuzz.set_xlabel('Fuzzification Index (m)')\n",
    "ax_xie_beni_fuzz.set_ylabel('Xie-Beni Index')\n",
    "ax_xie_beni_fuzz.set_title('Xie-Beni Index vs. Fuzzification Index')\n",
    "ax_xie_beni_fuzz.grid(True)\n",
    "ax_xie_beni_fuzz.set_xticks(m_values)\n",
    "\n",
    "# Adjust layout for Xie-Beni Index plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the Xie-Beni Index plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Gustafson-Kessel Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Perform GK Clustering on Iris dataset\n",
    "In this exercise you will perform  GK clustering on Iris dataset, test with up to 10 clusters and investigate how your choices affect accuracy. Generate a plot visualizing the optimal number of clusters using Sepal Length and Width.\n",
    "For that, you are provided with the code for GK clustering algorithm, you need to fill in the missing parts in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "For each number of clusters, perform Gustafson-Kessel clustering on the iris_data_normalized. You have to initialize the cluster_range, partition_matrices, cluster_centers_list\n",
    "\n",
    "You should return:\n",
    "   1. cluster_centers: The coordinates of the cluster centers.\n",
    "   2. partition_matrix: The membership matrix showing the degree of belonging of each data point to each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "cluster_range = range()\n",
    "partition_matrices = []\n",
    "cluster_centers_list = []\n",
    "\n",
    "# First loop: Perform clustering for each number of clusters\n",
    "for n_clusters in cluster_range:\n",
    "    # Perform clustering with the specified number of clusters\n",
    "    cl = Clusterer()\n",
    "    cluster_centers, partition_matrix, _ = cl.cluster()\n",
    "    \n",
    "    # Store the results\n",
    "    partition_matrices.append(partition_matrix)\n",
    "    cluster_centers_list.append(cluster_centers)\n",
    "# return partition_matrices\n",
    "# return cluster_centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`run the following code to estimate the accuracy and visualize your clusters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "# Second loop: Calculate accuracies\n",
    "for partition_matrix in partition_matrices:\n",
    "    # Assign each data point to the cluster with the highest membership value\n",
    "    assigned_clusters = np.argmax(partition_matrix, axis=1)\n",
    "    \n",
    "    # Generate the contingency matrix\n",
    "    contingency_matrix = confusion_matrix(true_labels, assigned_clusters)\n",
    "    \n",
    "    # Calculate accuracy by finding the most common true label in each cluster\n",
    "    correct_predictions = np.sum(np.max(contingency_matrix, axis=0))\n",
    "    accuracy = correct_predictions / len(true_labels)\n",
    "    \n",
    "    # Store the accuracy for the current number of clusters\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Subplot 1: Number of Clusters vs Accuracy\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(cluster_range, accuracies, marker='o', linestyle='-', color='b')\n",
    "plt.title('Clustering Accuracy vs. Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1.1)  # Set y-axis range\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.grid()\n",
    "\n",
    "# Subplot 2: Petal Length vs Petal Width for 3 Clusters (Clustered by GK)\n",
    "assigned_clusters_3 = np.argmax(partition_matrices[1], axis=1)  # Index 1 corresponds to 3 clusters\n",
    "cluster_centers_3 = cluster_centers_list[1]\n",
    "\n",
    "# Define colors for clusters\n",
    "colors = ['purple', 'green', 'orange']\n",
    "plt.subplot(1, 3, 2)\n",
    "for cluster in range(3):\n",
    "    plt.scatter(iris_data_normalized[assigned_clusters_3 == cluster, 2],\n",
    "                iris_data_normalized[assigned_clusters_3 == cluster, 3],\n",
    "                color=colors[cluster], label=f'Cluster {cluster + 1}', edgecolor='k')\n",
    "plt.scatter(cluster_centers_3[:, 2], cluster_centers_3[:, 3], marker='X', color='red', s=200, label='Cluster Centers')\n",
    "plt.title('Petal Length vs Petal Width for 3 Clusters')\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Subplot 3: Petal Length vs Petal Width with True Class Coloring\n",
    "true_colors = ['blue', 'red', 'yellow']  # Colors for true labels\n",
    "plt.subplot(1, 3, 3)\n",
    "for label in np.unique(true_labels):\n",
    "    plt.scatter(iris_data_normalized[true_labels == label, 2],\n",
    "                iris_data_normalized[true_labels == label, 3],\n",
    "                color=true_colors[label], label=f'True Class {label}', edgecolor='k', alpha=0.5)\n",
    "plt.title('Petal Length vs Petal Width - True Class')\n",
    "plt.xlabel('Petal Length')\n",
    "plt.ylabel('Petal Width')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
